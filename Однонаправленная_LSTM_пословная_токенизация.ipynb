{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Однонаправленная LSTM с пословной токенизацией:**"
      ],
      "metadata": {
        "id": "jvHkGWYuuUZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efe7hcXyuPb0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset, AUTOTUNE\n",
        "from tensorflow import keras\n",
        "import keras.layers as l\n",
        "\n",
        "from keras import models, callbacks, utils, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBNXFJWb4d0O"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "def request_url(url: str) -> BeautifulSoup:\n",
        "    request = requests.get(url)\n",
        "    soup = BeautifulSoup(request.content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "\n",
        "def get_url_data(url: str) -> List[str]:\n",
        "    soup = request_url(url)\n",
        "    scrapped_text = []\n",
        "\n",
        "    h1 = soup.h1.text.strip()\n",
        "    p = soup.find_all('p')\n",
        "\n",
        "    scrapped_text.append(h1)\n",
        "    scrapped_text.extend([p_i.text.strip() for p_i in p])\n",
        "\n",
        "    return scrapped_text\n",
        "\n",
        "def get_data(url: str) -> str:\n",
        "    soup = request_url(url)\n",
        "    text = []\n",
        "\n",
        "    text.extend([\n",
        "        soup.h1.text.strip() + '.',\n",
        "        soup.h2.text.strip() + '.',\n",
        "        soup.article.p.text.strip()\n",
        "    ])\n",
        "\n",
        "    url_chapters = [link.get('href') for link in soup.find_all('a', class_='link')]\n",
        "\n",
        "    for url in url_chapters:\n",
        "        scrapped_text = get_url_data(url)\n",
        "        text.extend(scrapped_text)\n",
        "\n",
        "    text = ' '.join(text).lower()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(url: str, file_name: str, path_dir: str = 'data/') -> str:\n",
        "    if os.path.isdir(path_dir) == False:\n",
        "        os.mkdir(path_dir)\n",
        "        print(f'Created {path_dir} directory')\n",
        "\n",
        "    path_file = f'{path_dir}{file_name}'\n",
        "\n",
        "    try:\n",
        "        with open(path_file, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        print('Uploaded from', path_file)\n",
        "\n",
        "    except:\n",
        "        text = get_data(url)\n",
        "\n",
        "        with open(path_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(text)\n",
        "\n",
        "        print('Saved to', path_file)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "gpQGvNh-ur2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Yidm1SsxhM",
        "outputId": "5880e579-3ff2-4a08-f5f9-2f2738990cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created data/ directory\n",
            "Saved to data/hpmor.txt\n"
          ]
        }
      ],
      "source": [
        "text = load_data('https://hpmor.ru/', 'hpmor.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhz_kviEPGNv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def split_into_sentences(text: str, regex: str = '[^а-яА-ЯёЁ0-9 ,-]') -> List[str]:\n",
        "    sentences = [re.sub(regex, '', s).strip() for s in text.split('.')]\n",
        "    sentences = list(filter(None, sentences))\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_voocL8OcHs"
      },
      "outputs": [],
      "source": [
        "text_word = split_into_sentences(text, \"[^а-яА-ЯёЁ0-9 ,-]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_word = text_word[:1000000]"
      ],
      "metadata": {
        "id": "rZbfjXefEBLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yashDdOFkE"
      },
      "source": [
        "**Токенизация**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVuPDLcJOCm2",
        "outputId": "3e9a48e7-b43d-4cae-c8c1-e3ed817fb74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', ',', '-', ..., 'ёовтен', 'ёрзал', 'ёрзали'], dtype='<U70')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dictionary = np.array(sorted(set(' '.join(text_word).split(' '))))\n",
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1GPlbkRP85K"
      },
      "outputs": [],
      "source": [
        "tokenizer_word_to_index_word = {char: i for i, char in enumerate(dictionary)}\n",
        "tokenizer_index_to_word_word = {i: char for i, char in enumerate(dictionary)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUMeNT_LQU_y"
      },
      "source": [
        "**Формирование датасета:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1u46qweQStm"
      },
      "outputs": [],
      "source": [
        "vectorized_text = np.array([tokenizer_word_to_index_word[word] for word in ' '.join(text_word).split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KgPSdQYQOLM"
      },
      "outputs": [],
      "source": [
        "vectorized_text = Dataset.from_tensor_slices(vectorized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g51vr9cmRr7F"
      },
      "outputs": [],
      "source": [
        "VOCAB_LEN = len(tokenizer_word_to_index_word.items())\n",
        "BATCH_SIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pexkOXF4R3N4"
      },
      "outputs": [],
      "source": [
        "sequences = vectorized_text.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0EGY8mPmiCz"
      },
      "outputs": [],
      "source": [
        "BATCHES_PER_EPOCH = len(sequences) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIMLnGX3SDql"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "def get_features_target(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    features = seq[:-1]\n",
        "    target = seq[1:]\n",
        "    return features, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjmtnEgpSGyP"
      },
      "outputs": [],
      "source": [
        "df = sequences.map(get_features_target).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "df = df.prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL3X6pD7SXOZ"
      },
      "source": [
        "**Построение и обучение модели:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-vDoNpMqurz"
      },
      "outputs": [],
      "source": [
        "vectorizer = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=len(dictionary),\n",
        "    input_shape=(1,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpvdYDddryYB"
      },
      "outputs": [],
      "source": [
        "import keras.layers as l\n",
        "model = keras.Sequential([\n",
        "    l.Embedding(len(dictionary), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
        "    l.LSTM(64, return_sequences=True, stateful=True),\n",
        "    l.Dense(len(dictionary))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcLAVTuTovGi",
        "outputId": "7ad21386-a4d4-465c-e172-7905a758e166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (100, None, 100)          6108100   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (100, None, 64)           42240     \n",
            "                                                                 \n",
            " dense (Dense)               (100, None, 61081)        3970265   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10120605 (38.61 MB)\n",
            "Trainable params: 10120605 (38.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqWZUuiG5zZT"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBvCSKQ053zH",
        "outputId": "6f4b7ea0-ca8b-4a00-f648-930b61862126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "53/53 [==============================] - 25s 415ms/step - loss: 10.1509 - accuracy: 0.0241\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 17s 318ms/step - loss: 8.3611 - accuracy: 0.0264\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 17s 324ms/step - loss: 8.2584 - accuracy: 0.0282\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 18s 333ms/step - loss: 8.2516 - accuracy: 0.0282\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 18s 343ms/step - loss: 8.2340 - accuracy: 0.0282\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 19s 355ms/step - loss: 8.1836 - accuracy: 0.0282\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 19s 356ms/step - loss: 8.1417 - accuracy: 0.0282\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 18s 347ms/step - loss: 8.1047 - accuracy: 0.0283\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 18s 345ms/step - loss: 8.0713 - accuracy: 0.0306\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 19s 350ms/step - loss: 8.0412 - accuracy: 0.0346\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 8.0141 - accuracy: 0.0363\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 7.9885 - accuracy: 0.0372\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 19s 350ms/step - loss: 7.9627 - accuracy: 0.0381\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 19s 349ms/step - loss: 7.9363 - accuracy: 0.0401\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.9069 - accuracy: 0.0416\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.8720 - accuracy: 0.0431\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.8335 - accuracy: 0.0465\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.7938 - accuracy: 0.0497\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.7537 - accuracy: 0.0524\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.7149 - accuracy: 0.0540\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.6772 - accuracy: 0.0560\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.6426 - accuracy: 0.0570\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.6095 - accuracy: 0.0579\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.5767 - accuracy: 0.0591\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.5431 - accuracy: 0.0609\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.5081 - accuracy: 0.0630\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.4711 - accuracy: 0.0654\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.4349 - accuracy: 0.0679\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.3992 - accuracy: 0.0705\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.3638 - accuracy: 0.0724\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.3287 - accuracy: 0.0744\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.2939 - accuracy: 0.0774\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.2592 - accuracy: 0.0805\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.2245 - accuracy: 0.0839\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 19s 351ms/step - loss: 7.1890 - accuracy: 0.0868\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.1533 - accuracy: 0.0895\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.1172 - accuracy: 0.0921\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.0817 - accuracy: 0.0948\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.0465 - accuracy: 0.0972\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 7.0126 - accuracy: 0.0996\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.9806 - accuracy: 0.1017\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.9462 - accuracy: 0.1041\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.9125 - accuracy: 0.1066\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.8796 - accuracy: 0.1089\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.8458 - accuracy: 0.1112\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.8128 - accuracy: 0.1133\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.7823 - accuracy: 0.1152\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.7543 - accuracy: 0.1172\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.7250 - accuracy: 0.1194\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.6941 - accuracy: 0.1222\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.6614 - accuracy: 0.1248\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.6271 - accuracy: 0.1275\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.5944 - accuracy: 0.1299\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.5635 - accuracy: 0.1317\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.5335 - accuracy: 0.1335\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.5045 - accuracy: 0.1354\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 6.4768 - accuracy: 0.1370\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 6.4514 - accuracy: 0.1383\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.4249 - accuracy: 0.1394\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.3976 - accuracy: 0.1410\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.3650 - accuracy: 0.1430\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 19s 352ms/step - loss: 6.3333 - accuracy: 0.1449\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.3032 - accuracy: 0.1466\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.2742 - accuracy: 0.1483\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.2468 - accuracy: 0.1496\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.2203 - accuracy: 0.1510\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.1951 - accuracy: 0.1522\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.1709 - accuracy: 0.1536\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.1446 - accuracy: 0.1548\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.1173 - accuracy: 0.1563\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.0884 - accuracy: 0.1584\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 6.0599 - accuracy: 0.1602\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.0318 - accuracy: 0.1620\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 6.0041 - accuracy: 0.1636\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.9772 - accuracy: 0.1652\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.9518 - accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.9277 - accuracy: 0.1682\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.9049 - accuracy: 0.1693\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.8823 - accuracy: 0.1705\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.8580 - accuracy: 0.1717\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.8324 - accuracy: 0.1729\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.8057 - accuracy: 0.1748\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.7783 - accuracy: 0.1769\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.7515 - accuracy: 0.1782\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.7255 - accuracy: 0.1797\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.7003 - accuracy: 0.1812\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.6762 - accuracy: 0.1828\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.6530 - accuracy: 0.1842\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.6320 - accuracy: 0.1852\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.6100 - accuracy: 0.1865\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.5867 - accuracy: 0.1879\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.5611 - accuracy: 0.1895\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.5349 - accuracy: 0.1915\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.5101 - accuracy: 0.1930\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.4853 - accuracy: 0.1945\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.4610 - accuracy: 0.1962\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.4364 - accuracy: 0.1980\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.4131 - accuracy: 0.1996\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 19s 353ms/step - loss: 5.3910 - accuracy: 0.2009\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 19s 354ms/step - loss: 5.3693 - accuracy: 0.2026\n"
          ]
        }
      ],
      "source": [
        "preds = model.fit(\n",
        "    df,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=BATCHES_PER_EPOCH\n",
        ")"
      ]
    }
  ]
}